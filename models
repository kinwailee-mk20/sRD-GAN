# Inference mode 
orig_img_size = (512, 512)
# Training mode 
input_img_size = (256, 256, 3)
# initialization 
kernel_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)
gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)
buffer_size = 256
batch_size = 1

# loss functions 
def generator_loss_fn(fake):
    fake_loss = adv_loss_fn(tf.ones_like(fake), fake)
    return fake_loss
    
def discriminator_loss_fn(real, fake):
    real_loss = adv_loss_fn(tf.ones_like(real), real)
    fake_loss = adv_loss_fn(tf.zeros_like(fake), fake)
    return (real_loss + fake_loss) * 0.5

# building blocks of sRDGAN 
def residual_block(
        x,
        activation,
        kernel_initializer=kernel_init,
        kernel_size=(3, 3),
        strides=(1, 1),
        padding="valid",
        gamma_initializer=gamma_init,
        use_bias=False,
        dropout=False,
        droprate=0.0,
):
    dim = x.shape[-1]
    input_tensor = x

    x = ReflectionPadding2D()(input_tensor)
    x = layers.Conv2D(
        dim,
        kernel_size,
        strides=strides,
        kernel_initializer=kernel_initializer,
        padding=padding,
        use_bias=use_bias,
    )(x)
    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)
    if dropout:
        x = layers.Dropout(droprate)(x)
    x = activation(x)

    x = ReflectionPadding2D()(x)
    x = layers.Conv2D(
        dim,
        kernel_size,
        strides=strides,
        kernel_initializer=kernel_initializer,
        padding=padding,
        use_bias=use_bias,
    )(x)
    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)
    if dropout:
        x = layers.Dropout(droprate)(x)
    x = layers.add([input_tensor, x])
    return x


def downsample(
        x,
        filters,
        activation,
        kernel_initializer=kernel_init,
        kernel_size=(3, 3),
        strides=(2, 2),
        padding="same",
        gamma_initializer=gamma_init,
        use_bias=False,
):
    x = layers.Conv2D(
        filters,
        kernel_size,
        strides=strides,
        kernel_initializer=kernel_initializer,
        padding=padding,
        use_bias=use_bias,
    )(x)
    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)
    if activation:
        x = activation(x)
    return x


def upsample(
        x,
        filters,
        activation,
        kernel_size=(3, 3),
        strides=(2, 2),
        padding="same",
        kernel_initializer=kernel_init,
        gamma_initializer=gamma_init,
        use_bias=False,
):
    x = layers.Conv2DTranspose(
        filters,
        kernel_size,
        strides=strides,
        padding=padding,
        kernel_initializer=kernel_initializer,
        use_bias=use_bias,
    )(x)
    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)
    if activation:
        x = activation(x)
    return x


# downsampling blocks, 9 residual blocks, 2 upsampling blocks
def get_resnet_generator(
        filters=64,
        num_downsampling_blocks=2,
        num_residual_blocks=9,
        num_upsample_blocks=2,
        gamma_initializer=gamma_init,
        name=None,
):
    img_input = layers.Input(shape=input_img_size, name=name + "_img_input")
    x = ReflectionPadding2D(padding=(3, 3))(img_input)
    x = layers.Conv2D(filters, (7, 7), kernel_initializer=kernel_init, use_bias=False)(x)
    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)
    x = layers.Activation("relu")(x)

    # Downsampling
    for _ in range(num_downsampling_blocks):
        filters *= 2
        x = downsample(x, filters=filters, activation=layers.Activation("relu"))

    # Residual blocks + sRD regularisation
    x = residual_block(x, activation=layers.Activation("relu"), dropout=True, droprate=0.2)  # 1
    x = residual_block(x, activation=layers.Activation("relu"), dropout=True, droprate=0.2)  # 2
    x = residual_block(x, activation=layers.Activation("relu"), dropout=True, droprate=0.2)  # 3
    x = residual_block(x, activation=layers.Activation("relu"), dropout=True, droprate=0.5)  # 4
    x = residual_block(x, activation=layers.Activation("relu"), dropout=True, droprate=0.5)  # 5
    x = residual_block(x, activation=layers.Activation("relu"), dropout=True, droprate=0.5)  # 6
    x = residual_block(x, activation=layers.Activation("relu"), dropout=True, droprate=0.5)  # 7
    x = residual_block(x, activation=layers.Activation("relu"), dropout=True, droprate=0.5)  # 8
    x = residual_block(x, activation=layers.Activation("relu"), dropout=True, droprate=0.5)  # 9

    # Upsampling
    for _ in range(num_upsample_blocks):
        filters //= 2
        x = upsample(x, filters, activation=layers.Activation("relu"))

    # Final block
    x = ReflectionPadding2D(padding=(3, 3))(x)
    x = layers.Conv2D(3, (7, 7), padding="valid")(x)
    x = layers.Activation("tanh")(x)

    model = keras.models.Model(img_input, x, name=name)
    return model


def get_discriminator(
        filters=64, kernel_initializer=kernel_init, num_downsampling=3, name=None
):
    img_input = layers.Input(shape=input_img_size, name=name + "_img_input")
    x = layers.Conv2D(
        filters,
        (4, 4),
        strides=(2, 2),
        padding="same",
        kernel_initializer=kernel_initializer,
    )(img_input)
    x = layers.LeakyReLU(0.2)(x)

    num_filters = filters
    for num_downsample_block in range(3):
        num_filters *= 2
        if num_downsample_block < 2:
            x = downsample(
                x,
                filters=num_filters,
                activation=layers.LeakyReLU(0.2),
                kernel_size=(4, 4),
                strides=(2, 2),
            )
        else:
            x = downsample(
                x,
                filters=num_filters,
                activation=layers.LeakyReLU(0.2),
                kernel_size=(4, 4),
                strides=(1, 1),
            )


    x = layers.Conv2D(
        1, (4, 4), strides=(1, 1), padding="same", kernel_initializer=kernel_initializer
    )(x)

    model = keras.models.Model(inputs=img_input, outputs=x, name=name)
    return model


# Get the generators
gen_G = get_resnet_generator(name="generator_G")
gen_F = get_resnet_generator(name="generator_F")

# Get the discriminators
disc_X = get_discriminator(name="discriminator_X")
disc_Y = get_discriminator(name="discriminator_Y")


# build the sRDGAN model
class sRDGAN(keras.Model):
    def __init__(
            self,
            generator_G,
            generator_F,
            discriminator_X,
            discriminator_Y,
            lambda_cycle=10.0,
            lambda_identity=0.05,
    ):
        super(sRDGAN, self).__init__()
        self.gen_G = generator_G
        self.gen_F = generator_F
        self.disc_X = discriminator_X
        self.disc_Y = discriminator_Y
        self.lambda_cycle = lambda_cycle
        self.lambda_identity = lambda_identity

    def compile(
            self,
            gen_G_optimizer,
            gen_F_optimizer,
            disc_X_optimizer,
            disc_Y_optimizer,
            gen_loss_fn,
            disc_loss_fn,
    ):
        super(sRDGAN, self).compile()
        self.gen_G_optimizer = gen_G_optimizer
        self.gen_F_optimizer = gen_F_optimizer
        self.disc_X_optimizer = disc_X_optimizer
        self.disc_Y_optimizer = disc_Y_optimizer
        self.generator_loss_fn = gen_loss_fn
        self.discriminator_loss_fn = disc_loss_fn
        self.cycle_loss_fn = keras.losses.MeanAbsoluteError()
        self.identity_loss_fn = keras.losses.MeanAbsoluteError()

    def train_step(self, batch_data):
        # x is Horse (base) and y is zebra (style)
        real_x, real_y = batch_data

        # For CycleGAN, we need to calculate different
        # kinds of losses for the generators and discriminators.
        # We will perform the following steps here:
        #
        # 1. Pass real images through the generators and get the generated images
        # 2. Pass the generated images back to the generators to check if we
        #    we can predict the original image from the generated image.
        # 3. Do an identity mapping of the real images using the generators.
        # 4. Pass the generated images in 1) to the corresponding discriminators.
        # 5. Calculate the generators total loss (adverserial + cycle + identity)
        # 6. Calculate the discriminators loss
        # 7. Update the weights of the generators
        # 8. Update the weights of the discriminators
        # 9. Return the losses in a dictionary

        with tf.GradientTape(persistent=True) as tape:

            # Horse to fake zebra
            fake_y = self.gen_G(real_x, training=True)
            # Cycle (Horse to fake zebra to fake horse): x -> y -> x
            cycled_x = self.gen_G(fake_y, training=True)
            # Identity mapping
            same_x = self.gen_G(real_y, training=True)


            # Discriminator output
            disc_real_y = self.disc_Y(real_y, training=True)
            disc_fake_y = self.disc_Y(fake_y, training=True)


            # forward gan loss
            gen_G_loss = self.generator_loss_fn(disc_fake_y)
            # pixel consistency loss
            loss_pix_x = self.identity_loss_fn(fake_y, real_x) * self.lambda_identity * gen_G_loss * 15
            # forward cycle loss
            cycle_loss_G = self.cycle_loss_fn(real_x, cycled_x) * self.lambda_cycle
            # forward id loss
            id_loss_G = (self.identity_loss_fn(real_x, same_x) * self.lambda_cycle * self.lambda_identity)
            # forward total
            total_loss_G = gen_G_loss + id_loss_G + cycle_loss_G
            disc_Y_loss = self.discriminator_loss_fn(disc_real_y, disc_fake_y)


        # get gradient
        grads_G = tape.gradient(total_loss_G, self.gen_G.trainable_variables)
        disc_Y_grads = tape.gradient(disc_Y_loss, self.disc_Y.trainable_variables)
        # update gradient
        self.gen_G_optimizer.apply_gradients(zip(grads_G, self.gen_G.trainable_variables))
        self.disc_Y_optimizer.apply_gradients(zip(disc_Y_grads, self.disc_Y.trainable_variables))


        with tf.GradientTape(persistent=True) as tape:
            # Zebra to fake horse -> y2x
            fake_x = self.gen_G(real_y, training=True)
            # Cycle (Zebra to fake horse to fake zebra) y -> x -> y
            cycled_y = self.gen_G(fake_x, training=True)
            same_y = self.gen_G(real_x, training=True)

            disc_real_x = self.disc_X(real_x, training=True)
            disc_fake_x = self.disc_X(fake_x, training=True)

            # reverse gan loss
            gen_F_loss = self.generator_loss_fn(disc_fake_x)
            # pixel consistency loss
            loss_pix_y = self.identity_loss_fn(fake_x, real_y) * self.lambda_identity * gen_F_loss * 15
            # reverse cycle loss
            cycle_loss_F = self.cycle_loss_fn(real_y, cycled_y) * self.lambda_cycle
            # forward id loss
            id_loss_F = (self.identity_loss_fn(real_y, same_y) * self.lambda_cycle * self.lambda_identity)
            # reverse total
            total_loss_F = gen_F_loss + id_loss_F + cycle_loss_F
            # Discriminator loss
            disc_X_loss = self.discriminator_loss_fn(disc_real_x, disc_fake_x)

        # get gradient
        grads_F = tape.gradient(total_loss_F, self.gen_G.trainable_variables)
        disc_X_grads = tape.gradient(disc_X_loss, self.disc_X.trainable_variables)

        # update gradient
        self.gen_G_optimizer.apply_gradients(zip(grads_F, self.gen_G.trainable_variables))
        self.disc_X_optimizer.apply_gradients(zip(disc_X_grads, self.disc_X.trainable_variables))


        return {
            "G_total_loss": total_loss_G,
            "F_total_loss": total_loss_F,
            "G_cycle_loss": cycle_loss_G,
            "F_cycle_loss": cycle_loss_F,
            "D_X_loss": disc_X_loss,
            "D_Y_loss": disc_Y_loss,
        }
